# Monitoramento de Pre√ßos de Milho e Vari√°veis Clim√°ticas - Passo Fundo/RS

Este projeto automatiza a coleta, processamento e visualiza√ß√£o de dados de pre√ßos de Milho (Pra√ßa Passo Fundo/RS - CMA) correlacionados com vari√°veis meteorol√≥gicas da regi√£o. A estrutura utiliza um pipeline de dados em nuvem para sustentar uma an√°lise econom√©trica robusta, quantificando o impacto de choques clim√°ticos no mercado f√≠sico regional, usando webscraping, API e Google cloud.

---

## Arquitetura do Sistema

O projeto utiliza uma abordagem de armazenamento em camadas para garantir a resili√™ncia dos dados:

1. **Coleta (Python):** Scripts executados via GitHub Actions extraem dados diariamente √†s 7 da manh√£ e mandam pra query.
2. **Armazenamento (BigQuery):** Data Warehouse centralizando dados hist√≥ricos (sql) e dados em tempo real (API) vindos das _actions_.
3. **Processamento (SQL):** Views otimizadas realizam o tratamento de tipos de dados e a unifica√ß√£o das s√©ries temporais, dentro do pr√≥prio BigQuery.
4. **An√°lise Econom√©trica (Jupyter):** Modelagem de causalidade, regress√£o linear (OLS) e an√°lise de volatilidade.
5. **Visualiza√ß√£o (Looker Studio):** Dashboard interativo para monitoramento de tend√™ncias em tempo real.

![PIPE](dashboard_milho.png/pipeline.png)

---

## Fontes de Dados

* **Precos do Milho:** Web Scraping customizado via BeautifulSoup e Pandas extraindo cota√ß√µes do mercado f√≠sico (CMA) diretamente do Not√≠cias Agr√≠colas.
* **Dados Clim√°ticos:** Open-Meteo API (Forecast e Archive) para captura de precipitacao e temperatura maxima.
* **Hist√≥rico:** Base de dados est√°tica importada manualmente da not√≠cias agr√≠colas no cloud (BigQuery) para garantir a continuidade da s√©rie desde 2025.

---

## Estrutura de Automa√ß√£o
<details>
<summary><b>Automacao (GitHub Actions)</b></summary>
A automa√ß√£o √© gerenciada via GitHub Actions. O workflow garante que o banco de dados e os backups em CSV sejam atualizados sem interven√ß√£o manual.

```yaml
name: Atualizacao Diaria
on:
  schedule:
    - cron: '0 7 * * *'
permissions:
  contents: write
jobs:
  run-etl:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Setup Python
        uses: actions/setup-python@v4
      - name: Execute
        run: |
          pip install pandas pandas-gbq
          python examples/teste_inmet.py
```
</details>


## Tratamento de Dados no BigQuery
<details>
<summary><b>Tratamento big Q</b></summary>

Foi implementada uma View SQL para resolver conflitos de tipos de dados e garantir a integridade do JOIN entre as tabelas de clima e mercado.

```sql
CREATE OR REPLACE VIEW `monitor-passofundo.clima_dados.visao_completa_clima_milho` AS
SELECT 
    c.data,
    c.precipitacao as chuva_mm,
    c.temp_max,
    m.preco_saca_reais as preco_milho
FROM `monitor-passofundo.clima_dados.historico_diario` AS c
LEFT JOIN `monitor-passofundo.clima_dados.precos_milho_cepea` AS m
    ON CAST(c.data AS DATE) = CAST(m.data AS DATE)
ORDER BY c.data DESC
```
</details>


## Gr√°fico no LOOKER

Esse gr√°fico atualiza automaticamente todo dia depois da automa√ß√£o nas >actions< ser feita.

![Dashboard de Monitoramento](dashboard_milho.png/dados_looker_webscrapi.png)

---

# An√°lise Econ√¥mica e Insights

## Metodologia e Intelig√™ncia Econom√©trica

Para superar a lacuna entre dados clim√°ticos (7 dias/semana) e cota√ß√µes de mercado (5 dias/semana), foi aplicada a t√©cnica de **Forward Fill (ffill)**. Isso permitiu que o modelo computasse chuvas ocorridas em finais de semana, que anteriormente eram descartadas, dobrando a robustez da amostra estat√≠stica.

### 1. Identifica√ß√£o de Causalidade (Lag Analysis)
Atrav√©s do Teste de **Causalidade de Granger**, identificou-se que o impacto m√°ximo da chuva sobre o pre√ßo ocorre com uma defasagem de 6 dias (Lag 6). Esse intervalo representa o tempo de resposta log√≠stica e o ajuste de oferta nas cooperativas locais.

![Dashboard de Monitoramento](dashboard_milho.png/causalidade_granger.png)


### 2. Modelo de Regress√£o Linear (OLS)
Utilizou-se o m√©todo de M√≠nimos Quadrados Ordin√°rios para quantificar o choque financeiro. O modelo apresentou um **p-valor de 0.007**, indicando signific√¢ncia estat√≠stica superior a 99%.

![Dashboard de Monitoramento](dashboard_milho.png/OLS.png)

$$\Delta Preco \approx 0.125 \times Chuva_{t-6}$$

**Insight:** Para cada 10mm de chuva acumulada em Passo Fundo, o pre√ßo da saca tende a subir, em m√©dia: **R$ 1,25** apos 6 dias.

### 3. An√°lise de Volatilidade e Risco
Calculou-se a volatilidade m√≥vel (Desvio Padr√£o de 7 dias) para medir o estresse do mercado:

$$\sigma = \sqrt{\frac{1}{N-1} \sum_{i=1}^{N} (x_i - \bar{x})^2}$$

Os resultados demonstram que picos de pluviosidade est√£o correlacionados ao aumento da incerteza de mercado, elevando o risco para produtores e compradores.

![Dashboard de Monitoramento](dashboard_milho.png/An√°lise_Volatilidade.png)

---

## Exemplo de Aplicacao: Predi√ß√£o de Curto Prazo

O modelo permite a gerac√£o de alertas e proje√ß√µes para a abertura de mercado. Abaixo, um exemplo de output gerado pelo sistema utilizando dados reais de 23/02/2026 para prever o impacto logistico na saca de milho no Lag 6 dia 02 de mar√ßo de 26

![Dashboard de Monitoramento](dashboard_milho.png/proje√ß√£o_milho_02-03.png)

*Nota: Esta proje√£o considera exclusivamente o choque de oferta derivado da pluviosidade regional, isolando vari√°veis de mercado externo.*

---

## Problemas enfrentados 
A principal barreira t√©cnica deste projeto foi a escassez de APIs gratuitas que fornecessem s√©ries hist√≥ricas longas para o mercado f√≠sico de milho no Brasil (Ticker)

* Limita√ß√£o da API: A solu√ß√£o encontrada foi fazer webscraping dos dados do site not√≠cias agr√≠colas

* Estrat√©gia de Mitiga√ß√£o: Para evitar uma an√°lise superficial limitada a um curto per√≠odo de tempo, foi adotada uma arquitetura h√≠brida. Realizou-se a extra√ß√£o manual de dados hist√≥ricos diretamente do not√≠cias agr√≠colas, que foram tratados e importados como uma base est√°tica no BigQuery.

* Resultado: Atrav√©s de uma opera√ß√£o de UNION via SQL, foi poss√≠vel consolidar o hist√≥rico legado com a automa√ß√£o presente, garantindo uma s√©rie temporal robusta para a aplica√ß√£o de modelos econom√©tricos.

---

## Como Instalar e Executar
<details>
<summary><b>Instala√ß√£o</b></summary>

* Pr√©-requisitos

* Python 3.9+

* Google Cloud Project com API do BigQuery ativa.

* Service Account com permissao de "Editor de Dados do BigQuery".

* GitHub Repository para configuracao de Actions.


## Configuracao Local

1. **Clonar o reposit√≥rio:**
```bash
   git clone [https://github.com/henriquereolonpain-sys/monitor-clima-pf.git](https://github.com/henriquereolonpain-sys/monitor-clima-pf.git)
   cd monitor-clima-pf
```

2. **Instalar Depend√™ncias:**
```Bash
    pip install -r requirements.txt
```

3. **Configurar credenciais:**
Salve o JSON da Service Account como google_credentials.json na raiz do projeto.

## Configura√ß√£o do GitHub Actions
Cadastre o segredo no GitHub (Settings > Secrets > Actions):
Nome do Secret--> GOOGLE_CREDENTIALS    
Descri√ß√£o -->   Conte√∫do completo do arquivo JSON da Service Account.

## Estrutura do Reposit√≥rio
1. .github/workflows/: Configura√ß√£o da rotina de execu√ß√£o di√°ria.

2. examples/teste_inmet.py: Script principal de ETL.

3. requirements.txt: Lista de bibliotecas necess√°rias.

4. *.csv: Arquivos de backup gerados automaticamente pelo pipeline.
</details>

Obrigado por ler at√© aqui, esse projeto totalizou 45-50 horas, um big abra√ßo! üêª